"""
IPFS å·¥å…·æ¨¡å— (Pinata REST API)

ç›´æ¥ä½¿ç”¨ Pinata REST APIï¼Œæ— éœ€ Node.js ä¸­é—´å±‚ã€‚

åŠŸèƒ½ï¼š
  - upload_json()      ä¸Šä¼  JSON æ•°æ®åˆ° IPFSï¼Œè¿”å› CID
  - upload_file()      ä¸Šä¼ æ–‡ä»¶åˆ° IPFSï¼Œè¿”å› CID
  - fetch_content()    é€šè¿‡ CID ä¸‹è½½å†…å®¹
  - fetch_and_verify() ä¸‹è½½ + SHA256 æ ¡éªŒï¼ˆSidecar åŒæ­¥æ—¶ä½¿ç”¨ï¼‰

ä½¿ç”¨åœºæ™¯å¯¹åº”ï¼š
  - Agent æ³¨å†Œ:  upload_json(metadata) â†’ CID â†’ registerAgent(did, cid)
  - è¯æ®ä¸Šä¼ :   upload_json(evidence) â†’ CID â†’ reportMisbehavior(agent, cid)
  - Sidecar åŒæ­¥: fetch_and_verify(cid) â†’ å¯ä¿¡å…ƒæ•°æ®
"""

import os
import json
import hashlib
import httpx
from infrastructure.load_config import load_key_config

# â”€â”€â”€ ä»ç»Ÿä¸€é…ç½®è¯»å– â”€â”€â”€
_config = load_key_config()
PINATA_JWT = _config.get("pinata_jwt", "")
GATEWAY_URL = _config.get("pinata_gateway", "")

# Pinata API åœ°å€
PINATA_API_URL = "https://uploads.pinata.cloud/v3/files"
PINATA_API_BASE = "https://api.pinata.cloud/v3"


def _get_headers():
    """æ„å»º Pinata API è®¤è¯å¤´"""
    if not PINATA_JWT:
        raise ValueError(
            "[IPFS] PINATA_JWT æœªè®¾ç½®ã€‚è¯·åœ¨ .env ä¸­è®¾ç½®æˆ–é€šè¿‡ç¯å¢ƒå˜é‡ä¼ å…¥ã€‚"
        )
    return {"Authorization": f"Bearer {PINATA_JWT}"}


def _get_gateway_url(cid: str) -> str:
    """æ„å»ºç½‘å…³è®¿é—® URL"""
    if GATEWAY_URL:
        return f"https://{GATEWAY_URL}/ipfs/{cid}"
    return f"https://gateway.pinata.cloud/ipfs/{cid}"


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# ä¸Šä¼ åŠŸèƒ½
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

def upload_json(data: dict, name: str = None) -> dict:
    """
    ä¸Šä¼  JSON æ•°æ®åˆ° IPFS

    Args:
        data: è¦ä¸Šä¼ çš„ JSON æ•°æ®ï¼ˆdictï¼‰
        name: å¯é€‰çš„æ–‡ä»¶åæ ‡è¯†

    Returns:
        dict: {"cid": "bafkrei...", "gateway_url": "https://..."}

    ç”¨æ³•:
        # ä¸Šä¼  Agent å…ƒæ•°æ®
        result = upload_json({
            "did": "did:ethr:sepolia:0x...",
            "capabilities": ["data-analysis"],
            "description": "..."
        })
        cid = result["cid"]  # ä¼ å…¥åˆçº¦ registerAgent(did, cid)
    """
    file_name = name or f"data-{int(__import__('time').time())}.json"
    json_bytes = json.dumps(data, ensure_ascii=False).encode("utf-8")

    # network=public æ˜¯å…³é”®ï¼å¦åˆ™é»˜è®¤ä¸Šä¼ åˆ° private ç½‘ç»œï¼Œä¸“å±ç½‘å…³æ— æ³•ç›´æ¥è®¿é—®
    files = {"file": (file_name, json_bytes, "application/json")}
    form_data = {"network": "public"}
    headers = _get_headers()

    response = httpx.post(PINATA_API_URL, headers=headers, files=files, data=form_data, timeout=30)
    response.raise_for_status()

    result = response.json()
    cid = result["data"]["cid"]

    return {
        "cid": cid,
        "gateway_url": _get_gateway_url(cid),
    }


def upload_file(file_path: str) -> dict:
    """
    ä¸Šä¼ æœ¬åœ°æ–‡ä»¶åˆ° IPFS

    Args:
        file_path: æœ¬åœ°æ–‡ä»¶è·¯å¾„

    Returns:
        dict: {"cid": "bafkrei...", "gateway_url": "https://..."}
    """
    if not os.path.exists(file_path):
        raise FileNotFoundError(f"[IPFS] æ–‡ä»¶ä¸å­˜åœ¨: {file_path}")

    file_name = os.path.basename(file_path)
    headers = _get_headers()

    with open(file_path, "rb") as f:
        files = {"file": (file_name, f)}
        form_data = {"network": "public"}
        response = httpx.post(PINATA_API_URL, headers=headers, files=files, data=form_data, timeout=60)
        response.raise_for_status()

    result = response.json()
    cid = result["data"]["cid"]

    return {
        "cid": cid,
        "gateway_url": _get_gateway_url(cid),
    }


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# ä¸‹è½½åŠŸèƒ½
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

# å…¬å…±ç½‘å…³åˆ—è¡¨ (ä½œä¸º Dedicated Gateway çš„å¤‡ä»½)
PUBLIC_GATEWAYS = [
    "https://gateway.pinata.cloud/ipfs",
    "https://ipfs.io/ipfs",
    "https://cloudflare-ipfs.com/ipfs",
    "https://dweb.link/ipfs",
]


def _fetch_from_url(url: str, timeout: int = 15) -> bytes:
    """å•ä¸€ URL ä¸‹è½½è¾…åŠ©å‡½æ•°"""
    try:
        # è‡ªå®šä¹‰ User-Agent é¿å…è¢« WAF æ‹¦æˆª
        response = httpx.get(
            url,
            timeout=timeout,
            follow_redirects=True,
            headers={"User-Agent": "PinataSidecar/1.0"},
        )
        response.raise_for_status()
        return response.content
    except Exception as e:
        raise RuntimeError(f"Failed {url}: {e}")


def fetch_race(cid: str, timeout: int = 30) -> bytes:
    """
    [æ ¸å¿ƒ] ç½‘å…³ç«é€Ÿæ¨¡å¼ä¸‹è½½
    åŒæ—¶è¯·æ±‚å¤šä¸ªç½‘å…³ï¼Œè¿”å›æœ€å¿«å“åº”çš„ç»“æœã€‚
    """
    import concurrent.futures

    # æ„å»ºå€™é€‰ç½‘å…³ URL åˆ—è¡¨
    urls = []

    # 1. ä¼˜å…ˆï¼šä¸“å±ç½‘å…³ (æœ€å¿«)
    gateway_base = (
        f"https://{GATEWAY_URL}" if GATEWAY_URL else "https://gateway.pinata.cloud"
    )
    urls.append(f"{gateway_base}/ipfs/{cid}")

    # 2. å¤‡é€‰ï¼šå…¬å…±ç½‘å…³ (æé«˜å¯ç”¨æ€§)
    for base_gw in PUBLIC_GATEWAYS:
        urls.append(f"{base_gw}/{cid}")

    # å»é‡
    urls = list(dict.fromkeys(urls))
    last_error = None

    # å¤šçº¿ç¨‹ç«é€Ÿ
    # æ³¨æ„: ä¸ä½¿ç”¨ 'with' ä¸Šä¸‹æ–‡ç®¡ç†å™¨ï¼Œé¿å…åœ¨è¿”å›æ—¶é˜»å¡ç­‰å¾…å…¶ä»–æ…¢é€Ÿç½‘å…³
    executor = concurrent.futures.ThreadPoolExecutor(max_workers=len(urls))
    try:
        future_to_url = {
            executor.submit(_fetch_from_url, url, timeout): url for url in urls
        }

        for future in concurrent.futures.as_completed(future_to_url):
            try:
                content = future.result()
                # æˆåŠŸï¼ç«‹å³å–æ¶ˆå…¶ä»–ä»»åŠ¡å¹¶è¿”å›ï¼Œä¸å†ç­‰å¾…
                executor.shutdown(wait=False, cancel_futures=True)
                return content
            except Exception as e:
                last_error = e
                continue
    finally:
        # å…œåº•æ¸…ç†
        executor.shutdown(wait=False, cancel_futures=True)

    raise RuntimeError(f"[IPFS] CID {cid} ä¸‹è½½å¤±è´¥ï¼Œæ‰€æœ‰ç½‘å…³å‡æ— å“åº”ã€‚Last Error: {last_error}")


def fetch_content(cid: str) -> bytes:
    """ä¿æŒæ¥å£å…¼å®¹ï¼Œå†…éƒ¨ä½¿ç”¨ç«é€Ÿæ¨¡å¼"""
    return fetch_race(cid)


def fetch_batch(cids: list[str], max_workers: int = 5) -> dict[str, bytes]:
    """
    [æ ¸å¿ƒ] æ‰¹é‡å¹¶å‘ä¸‹è½½

    Args:
        cids: CID åˆ—è¡¨
        max_workers: å¹¶å‘çº¿ç¨‹æ•°

    Returns:
        dict: {cid: bytes} æˆåŠŸçš„æ˜ å°„
    """
    import concurrent.futures

    results = {}
    print(f"ğŸ“¥ [Batch] å¼€å§‹æ‰¹é‡ä¸‹è½½ {len(cids)} ä¸ªæ–‡ä»¶ (å¹¶å‘: {max_workers})...")

    with concurrent.futures.ThreadPoolExecutor(max_workers=max_workers) as executor:
        # ä¸ºæ¯ä¸ª CID å¯åŠ¨ä¸€ä¸ªç«é€Ÿä¸‹è½½ä»»åŠ¡
        future_to_cid = {executor.submit(fetch_race, cid): cid for cid in cids}

        for future in concurrent.futures.as_completed(future_to_cid):
            cid = future_to_cid[future]
            try:
                data = future.result()
                results[cid] = data
            except Exception as e:
                print(f"  âŒ {cid[:15]}... Failed: {e}")

    return results


def fetch_json(cid: str) -> dict:
    """
    é€šè¿‡ CID ä¸‹è½½å¹¶è§£æ JSON

    Args:
        cid: IPFS å†…å®¹æ ‡è¯†ç¬¦

    Returns:
        dict: è§£æåçš„ JSON æ•°æ®
    """
    raw = fetch_content(cid)
    return json.loads(raw)


def fetch_and_verify(cid: str) -> dict:
    """
    ä¸‹è½½å†…å®¹å¹¶åš SHA256 å®Œæ•´æ€§æ ¡éªŒï¼ˆSidecar åŒæ­¥æ—¶ä½¿ç”¨ï¼‰

    å¯¹åº”è®¾è®¡æ–‡æ¡£ï¼š
    "Sidecar å¯¹ä¸‹è½½çš„å…ƒæ•°æ®å†…å®¹è¿›è¡Œ SHA256 è®¡ç®—ï¼Œ
     å°†è®¡ç®—ç»“æœä¸é“¾ä¸Šé”šå®šçš„ CID è¿›è¡Œä¸€è‡´æ€§æ¯”å¯¹"

    Args:
        cid: IPFS å†…å®¹æ ‡è¯†ç¬¦

    Returns:
        dict: {
            "content": dict,      # è§£æåçš„ JSON
            "raw": bytes,         # åŸå§‹å­—èŠ‚
            "sha256": str,        # SHA256 å“ˆå¸Œå€¼
            "cid": str,           # åŸå§‹ CID
            "verified": bool      # æ˜¯å¦ä¸‹è½½æˆåŠŸï¼ˆCID æœ¬èº«å°±æ˜¯å†…å®¹å¯»å€çš„æ ¡éªŒï¼‰
        }
    """
    raw = fetch_content(cid)
    sha256_hash = hashlib.sha256(raw).hexdigest()

    try:
        content = json.loads(raw)
    except json.JSONDecodeError:
        content = None

    return {
        "content": content,
        "raw": raw,
        "sha256": sha256_hash,
        "cid": cid,
        "verified": True,  # èƒ½é€šè¿‡ CID å–åˆ°å†…å®¹å³è¯´æ˜å†…å®¹ä¸å“ˆå¸ŒåŒ¹é…
    }


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# CLI å…¥å£ï¼ˆå¯ç›´æ¥è¿è¡Œæµ‹è¯•ï¼‰
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

if __name__ == "__main__":
    import sys

    if len(sys.argv) < 2:
        print("""
IPFS å·¥å…· (Python + Pinata REST API)
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

ç”¨æ³•:
  python infrastructure/ipfs.py upload     ä¸Šä¼ æµ‹è¯•å…ƒæ•°æ®
  python infrastructure/ipfs.py fetch CID  ä¸‹è½½å¹¶æ ¡éªŒ
        """)
        sys.exit(0)

    cmd = sys.argv[1]

    if cmd == "upload":
        test_metadata = {
            "did": "did:ethr:sepolia:0xTestAddress",
            "name": "Test Agent",
            "capabilities": ["test"],
            "description": "Test upload from Python",
            "createdAt": __import__("datetime").datetime.now().isoformat(),
        }
        print("ğŸ“¤ æ­£åœ¨ä¸Šä¼ æµ‹è¯•å…ƒæ•°æ®...")
        result = upload_json(test_metadata, "test-metadata.json")
        print(f"âœ… ä¸Šä¼ æˆåŠŸ!")
        print(f"   CID: {result['cid']}")
        print(f"   URL: {result['gateway_url']}")

    elif cmd == "fetch":
        if len(sys.argv) < 3:
            print("âŒ è¯·æä¾› CID: python infrastructure/ipfs.py fetch <CID>")
            sys.exit(1)
        cid = sys.argv[2]
        print(f"ğŸ“¥ æ­£åœ¨ä¸‹è½½ CID: {cid}...")
        try:
            result = fetch_and_verify(cid)
            print(f"ğŸ“„ å†…å®¹: {json.dumps(result['content'], indent=2, ensure_ascii=False)}")
            print(f"ğŸ”’ SHA256: {result['sha256']}")
        except Exception as e:
            print(f"âŒ ä¸‹è½½å¤±è´¥: {e}")

    elif cmd == "fetch_batch":
        # python infrastructure/ipfs.py fetch_batch cid1 cid2 ...
        if len(sys.argv) < 3:
            print("âŒ è¯·æä¾›è‡³å°‘ä¸€ä¸ª CID: python infrastructure/ipfs.py fetch_batch <CID1> <CID2> ...")
            sys.exit(1)
        cids = sys.argv[2:]
        results = fetch_batch(cids)
        print(f"âœ… å®Œæˆ! æˆåŠŸ: {len(results)}/{len(cids)}")
        for cid, data in results.items():
            print(f"  - {cid[:15]}...: {len(data)} bytes")
