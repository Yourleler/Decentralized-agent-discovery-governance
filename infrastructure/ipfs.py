"""
IPFS å·¥å…·æ¨¡å— (Pinata REST API)

ç›´æ¥ä½¿ç”¨ Pinata REST APIï¼Œæ— éœ€ Node.js ä¸­é—´å±‚ã€‚
æ”¯æŒå¼‚æ­¥å¹¶å‘ (AsyncIO) ä¸åŒæ­¥è°ƒç”¨ã€‚

åŠŸèƒ½ï¼š
  - upload_json() / upload_json_async()      ä¸Šä¼  JSON æ•°æ®åˆ° IPFSï¼Œè¿”å› CID
  - upload_file() / upload_file_async()      ä¸Šä¼ æ–‡ä»¶åˆ° IPFSï¼Œè¿”å› CID
  - fetch_content() / fetch_content_async()  é€šè¿‡ CID ä¸‹è½½å†…å®¹ (æ”¯æŒç«é€Ÿä¸ç¼“å­˜)
  - fetch_and_verify() / fetch_and_verify_async() ä¸‹è½½ + SHA256 æ ¡éªŒï¼ˆSidecar åŒæ­¥æ—¶ä½¿ç”¨ï¼‰
  - fetch_batch_async()                      æ‰¹é‡å¹¶å‘ä¸‹è½½ (Sidecar åˆå§‹åŒ–ä½¿ç”¨)

ä½¿ç”¨åœºæ™¯å¯¹åº”ï¼š
  - Agent æ³¨å†Œ:  upload_json(metadata) â†’ CID â†’ registerAgent(did, cid)
  - è¯æ®ä¸Šä¼ :   upload_json(evidence) â†’ CID â†’ reportMisbehavior(agent, cid)
  - Sidecar åŒæ­¥: fetch_and_verify_async(cid) â†’ å¯ä¿¡å…ƒæ•°æ®
"""


import json
import time
import hashlib
import asyncio
import logging
from pathlib import Path
from typing import Dict, Optional, List

import httpx
from tenacity import retry, stop_after_attempt, wait_exponential, retry_if_exception_type

from infrastructure.load_config import load_key_config

# â”€â”€â”€ é…ç½®ä¸å…¨å±€å˜é‡ â”€â”€â”€
LOGGER = logging.getLogger(__name__)#loggingæ˜¯ Python å†…ç½®çš„æ—¥å¿—æ¨¡å—

# å»¶è¿ŸåŠ è½½é…ç½®ï¼Œé¿å… import æ—¶å´©æºƒ
_CONFIG = None

def _get_config():
    global _CONFIG
    if _CONFIG is None:
        _CONFIG = load_key_config()
    return _CONFIG

# Pinata API åœ°å€
PINATA_API_URL = "https://uploads.pinata.cloud/v3/files"
PINATA_API_BASE = "https://api.pinata.cloud/v3"

# æœ¬åœ°ç¼“å­˜ç›®å½• (è®¾è®¡åŸåˆ™: Immutable Data Cache)
# ä½¿ç”¨é¡¹ç›®æ ¹ç›®å½•ä¸‹çš„ .ipfs_cacheï¼Œç¡®ä¿æ— è®ºä»å“ªé‡Œå¯åŠ¨ç¨‹åºç¼“å­˜ä½ç½®ä¸€è‡´
CACHE_DIR = Path(__file__).resolve().parent.parent / ".ipfs_cache"
CACHE_DIR.mkdir(parents=True, exist_ok=True)


# â”€â”€â”€ å¼‚å¸¸å®šä¹‰ â”€â”€â”€
class IPFSError(Exception):
    """IPFS æ“ä½œåŸºç±»å¼‚å¸¸"""
    pass#å ä½ç”¨çš„

class IPFSGatewayError(IPFSError):
    """ç½‘å…³è®¿é—®å¤±è´¥ (è¶…æ—¶/404/5xx)"""
    pass

class IPFSUploadError(IPFSError):
    """ä¸Šä¼ å¤±è´¥"""
    pass

class IPFSCacheError(IPFSError):
    """ç¼“å­˜è¯»å†™é”™è¯¯"""
    pass


# â”€â”€â”€ è¾…åŠ©å‡½æ•° â”€â”€â”€

def _get_headers() -> Dict[str, str]:
    """æ„å»º Pinata API è®¤è¯å¤´(jwtä»æ­¤åŠ è½½)"""
    config = _get_config()
    jwt = config.get("pinata_jwt", "")
    if not jwt:
        raise ValueError("[IPFS] PINATA_JWT æœªè®¾ç½®ã€‚è¯·åœ¨ .env ä¸­è®¾ç½®æˆ–é€šè¿‡ç¯å¢ƒå˜é‡ä¼ å…¥ã€‚")
    return {"Authorization": f"Bearer {jwt}"}

def _get_gateway_url(cid: str) -> str:
    """æ„å»ºé¦–é€‰ç½‘å…³è®¿é—® URL(ä¼˜å…ˆåŠ è½½é…ç½®ä¸­é¢„è®¾ç½‘å…³)"""
    config = _get_config()
    gateway = config.get("pinata_gateway", "")
    if gateway:
        return f"https://{gateway}/ipfs/{cid}"
    return f"https://gateway.pinata.cloud/ipfs/{cid}"

def _get_public_gateways() -> List[str]:
    """è·å–æ‰€æœ‰å¯ç”¨ç½‘å…³åˆ—è¡¨ (ä¸“å± + å…¬å…±)"""
    gateways = []
    # 1. ä¼˜å…ˆï¼šä¸“å±ç½‘å…³
    config = _get_config()
    gateway = config.get("pinata_gateway", "")
    if gateway:
        gateways.append(f"https://{gateway}/ipfs")
    else:
        # Default Pinata Gateway
        gateways.append("https://gateway.pinata.cloud/ipfs")
    
    # 2. å¤‡é€‰ï¼šå…¬å…±ç½‘å…³
    public_gateways = [
        "https://ipfs.io/ipfs",
        "https://cloudflare-ipfs.com/ipfs",
        "https://dweb.link/ipfs",
    ]
    gateways.extend(public_gateways)#è¿½åŠ ä½†ä¸å»é‡
    # å»é‡
    return list(dict.fromkeys(gateways))


# â”€â”€â”€ æ ¸å¿ƒï¼šç¼“å­˜æœºåˆ¶ â”€â”€â”€

def _read_cache(cid: str) -> Optional[bytes]:
    """
    ä»æœ¬åœ°æ–‡ä»¶ç³»ç»Ÿè¯»å–ç¼“å­˜ (Raw Bytes)
    - æ–‡ä»¶åå³ CIDï¼Œæ— åç¼€ï¼šä¿æŒå†…å®¹å¯»å€çš„çº¯ç²¹æ€§ï¼Œé¿å…çŒœæµ‹æ–‡ä»¶ç±»å‹ã€‚
    - äºŒè¿›åˆ¶è¯»å– (bytes)ï¼šç¡®ä¿ SHA256 æ ¡éªŒç»å¯¹ä¸€è‡´ï¼Œä¸”æ”¯æŒä»»æ„æ ¼å¼ (JSON/å›¾ç‰‡/PDF)ã€‚
    """
    cache_path = CACHE_DIR / cid #/æ˜¯pathlib.Pathè·¯å¾„æ‹¼æ¥çš„é‡è½½ç¬¦
    if cache_path.exists():
        try:
            return cache_path.read_bytes()
        except Exception as e:
            LOGGER.warning(f"[IPFS] Cache read failed for {cid}: {e}")
    return None

def _write_cache(cid: str, content: bytes):
    """å†™å…¥æœ¬åœ°æ–‡ä»¶ç³»ç»Ÿç¼“å­˜ (Immutable)"""
    try:
        cache_path = CACHE_DIR / cid
        # åŸå­å†™å…¥ï¼šå…ˆå†™ä¸´æ—¶æ–‡ä»¶å†é‡å‘½åï¼Œé˜²æ­¢å†™å…¥ä¸­æ–­å¯¼è‡´æ–‡ä»¶æŸå
        temp_path = cache_path.with_suffix(".tmp")#åŠ åç¼€,ç”¨è¿™ä¸ªå¯ä»¥æœ‰æ›¿æ¢åç¼€çš„åŠŸèƒ½
        temp_path.write_bytes(content)
        temp_path.rename(cache_path)#é‡å‘½å
    except Exception as e:
        LOGGER.warning(f"[IPFS] Cache write failed for {cid}: {e}")


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# å¼‚æ­¥ä¸Šä¼ åŠŸèƒ½ (Async Upload)
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

async def upload_json_async(data: dict, name: str = None) -> dict:#asyncè¡¨æ˜å…¶æ˜¯å¼‚æ­¥ ä¸ºåç¨‹,éœ€è¦ç”¨awaitè°ƒç”¨åç¨‹æŒ‚èµ·
    """[Async] ä¸Šä¼  JSON æ•°æ®åˆ° IPFS"""
    file_name = name or f"data-{int(time.time())}.json"
    json_bytes = json.dumps(data, ensure_ascii=False).encode("utf-8")
    
    # Pinata V3 multipart/form-data æœºåˆ¶:
    # 1. files: æ”¾å…¥æ–‡ä»¶å¯¹è±¡(keyæ ‡è¯†ä¸ºæ–‡ä»¶)ã€‚httpx ä¼šè‡ªåŠ¨ç”Ÿæˆ filename å’Œ Content-Type å¤´ï¼ŒPinata è¯†åˆ«ä¸ºæ–‡ä»¶æµã€‚
    files = {"file": (file_name, json_bytes, "application/json")}
    
    # 2. data: æ”¾å…¥æ™®é€šå­—æ®µã€‚httpx å¤„ç†ä¸ºç®€å•é”®å€¼å¯¹ã€‚æŒ‡å®š "network": "public" ä»¥å…è®¸å…¬å…±ç½‘å…³è®¿é—®ã€‚Pinata V3 é»˜è®¤private
    form_data = {"network": "public"}
    
    try:
        async with httpx.AsyncClient() as client:
            response = await client.post(
                PINATA_API_URL, 
                headers=_get_headers(), 
                files=files, 
                data=form_data, 
                timeout=30.0
            )
            response.raise_for_status()
            result = response.json()
            cid = result["data"]["cid"]
            
            # é¡ºä¾¿å†™å…¥ç¼“å­˜ï¼Œè‡ªå·±ä¸Šä¼ çš„è‚¯å®šå¯ä¿¡
            _write_cache(cid, json_bytes)
            
            return {
                "cid": cid,
                "gateway_url": _get_gateway_url(cid),
            }
    except httpx.HTTPError as e:
        raise IPFSUploadError(f"Upload failed: {str(e)}") from e

async def upload_file_async(file_path: str) -> dict:
    """[Async] ä¸Šä¼ æœ¬åœ°æ–‡ä»¶åˆ° IPFS"""
    path = Path(file_path)
    if not path.exists():
        raise FileNotFoundError(f"[IPFS] æ–‡ä»¶ä¸å­˜åœ¨: {file_path}")

    file_name = path.name
    # è¯»å–æ–‡ä»¶å†…å®¹ä»¥ä¾¿ä¸Šä¼ 
    content = path.read_bytes()
    files = {"file": (file_name, content)}
    form_data = {"network": "public"}

    try:
        async with httpx.AsyncClient() as client:
            response = await client.post(
                PINATA_API_URL, 
                headers=_get_headers(), 
                files=files, 
                data=form_data, 
                timeout=60.0
            )
            response.raise_for_status()
            result = response.json()
            cid = result["data"]["cid"]
            
            _write_cache(cid, content)
            
            return {
                "cid": cid,
                "gateway_url": _get_gateway_url(cid),
            }
    except httpx.HTTPError as e:
        raise IPFSUploadError(f"File upload failed: {str(e)}") from e


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# å¼‚æ­¥ä¸‹è½½åŠŸèƒ½ (Async Fetch & Race)
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

async def _fetch_url_async(client: httpx.AsyncClient, url: str) -> bytes:
    """å•ä¸ª URL ä¸‹è½½åç¨‹"""
    try:
        resp = await client.get(
            url, 
            timeout=10.0, 
            follow_redirects=True,
            headers={"User-Agent": "PinataSidecar/2.0"}
        )
        resp.raise_for_status()
        return resp.content
    except Exception as e:
        # ä»…ç”±äºç«é€Ÿéœ€è¦ï¼Œè¿™é‡ŒæŠ›å‡ºå¼‚å¸¸ä¾›ä¸Šå±‚æ•è·ï¼Œä¸æ‰“å°æ—¥å¿—ä»¥å…åˆ·å±
        raise IPFSGatewayError(f"Failed {url}") from e

@retry(
    stop=stop_after_attempt(3), 
    wait=wait_exponential(multiplier=1, min=2, max=10),
    retry=retry_if_exception_type(IPFSGatewayError),
    reraise=True
)#é‡è¯•3æ¬¡ï¼Œæ¯æ¬¡ç­‰å¾…æ—¶é—´æŒ‡æ•°çº§å¢é•¿ï¼Œæœ€å¤šç­‰å¾…10ç§’ï¼Œé‡è¯•ç±»å‹ä¸ºIPFSGatewayErrorï¼Œé‡è¯•åé‡æ–°æŠ›å‡ºå¼‚å¸¸
async def fetch_race_async(cid: str) -> bytes:
    """
    [æ ¸å¿ƒ] å¼‚æ­¥ç½‘å…³ç«é€Ÿä¸‹è½½
    ä¼˜å…ˆæŸ¥ç¼“å­˜ -> ç¼“å­˜æœªå‘½ä¸­ -> å¹¶å‘è¯·æ±‚å¤šä¸ªç½‘å…³ -> å–æœ€å¿« -> å†™å…¥ç¼“å­˜
    """
    # 1. æŸ¥ç¼“å­˜
    cached = _read_cache(cid)
    if cached:
        return cached

    # 2. å‡†å¤‡ç½‘å…³åˆ—è¡¨
    gateways = _get_public_gateways()
    urls = [f"{gw}/{cid}" for gw in gateways]
    
    # 3. å¹¶å‘ç«é€Ÿ
    async with httpx.AsyncClient() as client:
        # åˆ›å»ºè¿™ç»„ä»»åŠ¡
        tasks = [
            asyncio.create_task(_fetch_url_async(client, url)) 
            for url in urls
        ]
        
        try:
            # as_completed è¿”å› iteratorï¼ŒæŒ‰å®Œæˆé¡ºåº yield (è°å¿«è°å…ˆå‡º)ã€‚
            # è¿™é‡Œçš„æœºåˆ¶ç±»ä¼¼äºï¼š
            # 1. create_task å¼€å¯äº†"è™šæ‹Ÿæœº/æ²™ç›’"ï¼Œä»»åŠ¡åœ¨å…¶ä¸­ç‹¬ç«‹è¿è¡Œï¼Œå¼‚å¸¸ä¹Ÿè¢«éš”ç¦»åœ¨ Task å¯¹è±¡ä¸­ã€‚
            # 2. await future æ˜¯"å¼€ç®±"è¿‡ç¨‹ï¼šå°†æ²™ç›’å†…çš„ç»“æœï¼ˆæ•°æ®æˆ–å¼‚å¸¸ï¼‰é‡Šæ”¾åˆ°ä¸»æ§æµç¨‹ä¸­ã€‚
            #    - è‹¥æˆåŠŸï¼šæ‹¿åˆ°æ•°æ®ã€‚
            #    - è‹¥å¤±è´¥ï¼šåœ¨æ­¤å¤„é‡æ–°æŠ›å‡ºå¼‚å¸¸ï¼ˆ"å¼•çˆ†"é”™è¯¯ï¼‰ï¼Œè¢«ä¸‹æ–¹ except æ•è·ä»è€Œå¿½ç•¥è¯¥å¤±è´¥èŠ‚ç‚¹ã€‚
            for future in asyncio.as_completed(tasks):
                try:
                    content = await future
                    # æœ‰ä¸€ä¸ªæˆåŠŸäº†ï¼Œå–æ¶ˆå…¶ä»–ä»»åŠ¡
                    for t in tasks:
                        if not t.done():
                            t.cancel()
                    
                    # å†™å…¥ç¼“å­˜
                    _write_cache(cid, content)
                    return content
                except Exception:
                    # è¿™ä¸ª task å¤±è´¥äº†ï¼Œç»§ç»­ç­‰ä¸‹ä¸€ä¸ª
                    continue
            
        except asyncio.CancelledError:
            # å¦‚æœå¤–éƒ¨å–æ¶ˆäº†æˆ‘ä»¬ï¼Œæˆ‘ä»¬ä¹Ÿå–æ¶ˆå­ä»»åŠ¡
            for t in tasks:
                if not t.done():
                    t.cancel()
            raise

    # æ‰€æœ‰éƒ½å¤±è´¥äº†
    raise IPFSGatewayError(f"[IPFS] All gateways failed for CID {cid}")

async def fetch_json_async(cid: str) -> dict:
    """[Async] ä¸‹è½½å¹¶è§£æ JSON"""
    content = await fetch_race_async(cid)
    try:
        return json.loads(content)
    except json.JSONDecodeError as e:
        raise ValueError(f"Invalid JSON content for CID {cid}") from e

async def fetch_and_verify_async(cid: str) -> dict:
    """
    [Async] ä¸‹è½½ + æ ¡éªŒ (Sidecar æ ¸å¿ƒé€»è¾‘)
    """
    content_bytes = await fetch_race_async(cid)
    
    # è®¡ç®— SHA256
    sha256_hash = hashlib.sha256(content_bytes).hexdigest()
    
    # å°è¯•è§£æ JSON
    try:
        data = json.loads(content_bytes)
    except json.JSONDecodeError:
        data = None
        
    return {
        "content": data,
        "raw": content_bytes,
        "sha256": sha256_hash,
        "cid": cid,
        # ç›®å‰ verification ä¾èµ–äº HTTPS ç½‘å…³çš„å¯ä¿¡åº¦ã€‚
        # ä¸¥æ ¼çš„ CID æ ¡éªŒéœ€è¦æœ¬åœ°å¤åˆ» IPFS çš„ DAG åˆ†å—ä¸å“ˆå¸Œç®—æ³• (éœ€å¼•å…¥ ipfs-cid åº“)ï¼Œ
        # å¯¹äº Agent Metadata è¿™ç§å°æ–‡ä»¶ï¼ŒRisk è¾ƒä½ï¼Œæš‚æ—¶é€šè¿‡ SHA256 ç”¨äºäº‹åå®¡è®¡(Metadataé‡Œé¢æœ€å¥½æœ€å¸¦hashç”¨äºæ ¡éªŒ)
        "verified": True 
    }

async def fetch_batch_async(cids: List[str], max_workers: int = 5) -> Dict[str, bytes]:
    """
    [Async] æ‰¹é‡å¹¶å‘ä¸‹è½½ (åˆ©ç”¨ Semaphore æ§åˆ¶å¹¶å‘åº¦)
    
    æ³¨æ„ï¼šé‡‡ç”¨ Best-Effort ç­–ç•¥ã€‚
    - ä¸‹è½½å¤±è´¥çš„ä»»åŠ¡ä¼šè¢«æ²‰é»˜ä¸¢å¼ƒ (åªæ‰“å° ERROR æ—¥å¿—)ã€‚
    - è¿”å›çš„å­—å…¸å¯èƒ½å°‘äºè¾“å…¥çš„ cids æ•°é‡ã€‚
    """
    sem = asyncio.Semaphore(max_workers)
    results = {}
    
    async def _bounded_fetch(cid):
        # async with sem: ä¸Šä¸‹æ–‡ç®¡ç†å™¨ (Context Manager)
        # 1. è‡ªåŠ¨ç®¡ç†å‡­è¯ï¼šè¿›å…¥æ—¶ acquire() æ‹¿é”/é¢†è¯ï¼Œé€€å‡ºæ—¶ release() è¿˜é”/å½’è¿˜ã€‚
        # 2. ä¹Ÿæ˜¯å¹¶å‘æ§åˆ¶çš„æ ¸å¿ƒï¼š
        #    - è¿™æ˜¯ä¸€ä¸ª"åç¨‹ç‰ˆ"çš„ä¿¡å·é‡ï¼Œéç³»ç»Ÿçº¿ç¨‹ã€‚
        #    - é™åˆ¶åŒæ—¶å¤„äº"æ´»è·ƒçŠ¶æ€" (Running) çš„åç¨‹æ•°é‡ï¼Œé˜²æ­¢ IO çˆ†ç‚¸ã€‚
        #    - ç›¸æ¯”çº¿ç¨‹æ±  (ThreadPool)ï¼Œåç¨‹åˆ‡æ¢å¼€é”€æå°ï¼Œæ›´é€‚åˆé«˜å¹¶å‘ç½‘ç»œè¯·æ±‚ã€‚
        async with sem:
            try:
                data = await fetch_race_async(cid)
                return cid, data
            except Exception as e:
                LOGGER.error(f"[IPFS] Batch fetch failed for {cid}: {e}")
                return cid, None

    tasks = [asyncio.create_task(_bounded_fetch(cid)) for cid in cids]
    # await asyncio.gather: "é›†ä¸­æ‹†ç®±"
    # 1. å¹¶å‘æ‰§è¡Œæ‰€æœ‰ Taskï¼Œå¹¶ç­‰å¾…å…¨éƒ¨å®Œæˆ (Gathering)ã€‚
    # 2. æŒ‰è¾“å…¥é¡ºåºè¿”å›ç»“æœåˆ—è¡¨: [(cid1, data1), (cid2, None), ...]ã€‚
    #    å³ä½¿ä¸­é—´æœ‰çš„ä»»åŠ¡å¾ˆå¿«å®Œæˆï¼Œä¹Ÿä¼šåœ¨åˆ—è¡¨ä¸­å å¥½ä½å­ç­‰å¾…å…¶ä»–ä»»åŠ¡ã€‚
    done_results = await asyncio.gather(*tasks)
    
    # è¿‡æ»¤å¤±è´¥ä»»åŠ¡ (Best-Effort ç­–ç•¥)
    # è¿™é‡Œçš„é€»è¾‘æ˜¯ï¼šåªè¿”å›ä¸‹è½½æˆåŠŸçš„æ•°æ®ï¼Œæ‚„æ‚„ä¸¢å¼ƒå¤±è´¥çš„ (None)ã€‚
    # è°ƒç”¨è€…æ‹¿åˆ°çš„ results å­—å…¸å¯èƒ½å°‘äºå…¥å‚ cids çš„æ•°é‡ã€‚
    # è‹¥éœ€ä¸¥æ ¼ä¸€è‡´æ€§ (All-or-Nothing)ï¼Œè°ƒç”¨è€…éœ€è‡ªè¡Œæ¯”å¯¹ results.keys() ä¸ cidsã€‚
    for cid, data in done_results:
        if data is not None:
            results[cid] = data
            
    return results


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# åŒæ­¥å…¼å®¹å±‚ (Sync Wrappers for CLI/Legacy)
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

def _run_sync(coro):
    """
    å®‰å…¨åœ°åŒæ­¥æ‰§è¡Œå¼‚æ­¥åç¨‹ã€‚
    - å¦‚æœå½“å‰æ²¡æœ‰äº‹ä»¶å¾ªç¯ (CLI åœºæ™¯)ï¼šç”¨ asyncio.run()
    - å¦‚æœå½“å‰å·²æœ‰äº‹ä»¶å¾ªç¯ (è¢« FastAPI/uvicorn è°ƒç”¨)ï¼šç”¨ loop.run_until_complete()
    æ³¨æ„ï¼šåœ¨ FastAPI ä¸­åº”ç›´æ¥ä½¿ç”¨ async ç‰ˆæœ¬ï¼Œæ­¤å¤„ä»…ä½œå…œåº•å…¼å®¹ã€‚
    """
    try:
        loop = asyncio.get_running_loop()#è·å–å½“å‰æ­£åœ¨è¿è¡Œçš„äº‹ä»¶å¾ªç¯çš„å‡½æ•°
    except RuntimeError:
        # æ²¡æœ‰æ­£åœ¨è¿è¡Œçš„äº‹ä»¶å¾ªç¯ï¼Œå®‰å…¨ä½¿ç”¨ asyncio.run()å¯åŠ¨äº‹ä»¶å¾ªç¯å¹¶æ‰§è¡Œä¼ å…¥çš„åç¨‹
        return asyncio.run(coro)
    else:
        # å·²æœ‰äº‹ä»¶å¾ªç¯(tryä¸­æœªæŠ›å‡ºå¼‚å¸¸) -> ä¸èƒ½ç”¨ asyncio.run()ï¼Œ
        # åˆ›å»ºæ–°çº¿ç¨‹æ‰§è¡Œä»¥é¿å…é˜»å¡äº‹ä»¶å¾ªç¯
        import concurrent.futures
        with concurrent.futures.ThreadPoolExecutor(max_workers=1) as pool:
            return pool.submit(asyncio.run, coro).result()

def upload_json(data: dict, name: str = None) -> dict:
    """[Sync] upload_json_async çš„åŒæ­¥å°è£…"""
    return _run_sync(upload_json_async(data, name))

def upload_file(file_path: str) -> dict:
    """[Sync] upload_file_async çš„åŒæ­¥å°è£…"""
    return _run_sync(upload_file_async(file_path))

def fetch_content(cid: str) -> bytes:
    """[Sync] fetch_race_async çš„åŒæ­¥å°è£…"""
    return _run_sync(fetch_race_async(cid))

def fetch_json(cid: str) -> dict:
    """[Sync] fetch_json_async çš„åŒæ­¥å°è£…"""
    return _run_sync(fetch_json_async(cid))

def fetch_and_verify(cid: str) -> dict:
    """[Sync] fetch_and_verify_async çš„åŒæ­¥å°è£…"""
    return _run_sync(fetch_and_verify_async(cid))

def fetch_batch(cids: List[str], max_workers: int = 5) -> Dict[str, bytes]:
    """
    [Sync] fetch_batch_async çš„åŒæ­¥å°è£…
    åŒæ ·é‡‡ç”¨ Best-Effort ç­–ç•¥ï¼Œå¤±è´¥çš„ä»»åŠ¡ä¼šè¢«ä¸¢å¼ƒã€‚
    """
    return _run_sync(fetch_batch_async(cids, max_workers))


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# CLI å…¥å£
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

if __name__ == "__main__":
    import sys
    
    # é…ç½®æ—¥å¿—è¾“å‡ºåˆ°æ§åˆ¶å°
    logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')

    if len(sys.argv) < 2:
        print("""
IPFS å·¥å…· (Async/Sync Hybrid)
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

ç”¨æ³•:
  python infrastructure/ipfs.py upload     ä¸Šä¼ æµ‹è¯•å…ƒæ•°æ®
  python infrastructure/ipfs.py fetch CID  ä¸‹è½½å¹¶æ ¡éªŒ
        """)
        sys.exit(0)

    cmd = sys.argv[1]

    if cmd == "upload":
        test_metadata = {
            "did": "did:ethr:sepolia:0xTestAddress",
            "name": "Async IPFS Test",
            "description": "Uploaded via new async client",
            "timestamp": time.time(),
        }
        print("ğŸ“¤ æ­£åœ¨ä¸Šä¼ æµ‹è¯•å…ƒæ•°æ® (Sync Wrapper)...")
        try:
            result = upload_json(test_metadata, "async-test.json")
            print(f"âœ… ä¸Šä¼ æˆåŠŸ!")
            print(f"   CID: {result['cid']}")
            print(f"   URL: {result['gateway_url']}")
        except Exception as e:
            print(f"âŒ ä¸Šä¼ å¤±è´¥: {e}")

    elif cmd == "fetch":
        if len(sys.argv) < 3:
            print("âŒ è¯·æä¾› CID")
            sys.exit(1)
        cid = sys.argv[2]
        print(f"ğŸ“¥ æ­£åœ¨ä¸‹è½½ CID: {cid} (from Cache or Network)...")
        try:
            result = fetch_and_verify(cid)
            print(f"ğŸ“„ å†…å®¹: {json.dumps(result['content'], indent=2, ensure_ascii=False)}")
            print(f"ğŸ”’ SHA256: {result['sha256']}")
            
            # éªŒè¯ç¼“å­˜æ˜¯å¦å­˜åœ¨
            cache_path = CACHE_DIR / cid
            if cache_path.exists():
                print("ğŸ’¾ æœ¬åœ°ç¼“å­˜å·²å®Œæˆ")
        except Exception as e:
            print(f"âŒ ä¸‹è½½å¤±è´¥: {e}")
